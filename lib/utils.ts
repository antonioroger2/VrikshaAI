/**
 * Utility functions for VRIKSHA.ai
 */

import { waitForCapacity } from './redis-queue';

// â”€â”€ Provider type â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

export type ApiProvider = 'groq' | 'bedrock' | 'qwen' | 'gemini';

// â”€â”€ Dumb exponential backoff (internal legacy / kept for non-LLM calls) â”€â”€â”€â”€â”€â”€

export async function withRetries<T>(
  apiCall: () => Promise<T>,
  maxRetries = 3
): Promise<T> {
  for (let attempt = 1; attempt <= maxRetries; attempt++) {
    try {
      return await apiCall();
    } catch (error) {
      if (attempt === maxRetries) throw error;

      const waitTime = Math.pow(2, attempt) * 1000; // 2s, 4s, 8sâ€¦
      console.warn(`API error, retrying in ${waitTime}ms (Attempt ${attempt + 1}/${maxRetries})...`, error);
      await new Promise(resolve => setTimeout(resolve, waitTime));
    }
  }
  throw new Error("API request failed after maximum retries.");
}

// â”€â”€ Smart Redis-backed rate-limit queue â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

/**
 * Wraps an API call with:
 *   1. Redis token-bucket gating (waitlist if RPM/TPM saturated)
 *   2. 3-attempt retry on transient errors / 429s
 *
 * @param provider        - Which AI provider ('groq' | 'bedrock' | 'qwen' | 'gemini')
 * @param estimatedTokens - Expected token usage for this call (used for TPM tracking)
 * @param apiCall         - The actual fetch/API call to make
 * @param onStatus        - Optional UI status callback; fires on waitlist and retries
 * @param maxRetries      - Number of attempts after the queue clears (default 3)
 */
export async function withSmartRetries<T>(
  provider: ApiProvider,
  estimatedTokens: number,
  apiCall: () => Promise<T>,
  onStatus?: (status: string) => void,
  maxRetries = 3
): Promise<T> {
  for (let attempt = 1; attempt <= maxRetries; attempt++) {
    try {
      // â”€â”€ 1. Gate on the Redis token bucket â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
      await waitForCapacity(provider, estimatedTokens, (position, waitTimeMs) => {
        const seconds = Math.ceil(waitTimeMs / 1000);
        onStatus?.(
          `ðŸš¦ High traffic. Waitlisted at position ${position}. Retrying in ${seconds}sâ€¦`
        );
      });

      // â”€â”€ 2. Fire the API call â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
      return await apiCall();

    } catch (error: unknown) {
      if (attempt === maxRetries) throw error;

      // Surface 429s with a longer back-off; other errors use exponential
      const msg = error instanceof Error ? error.message : String(error);
      const isRateLimit =
        msg.includes('429') ||
        (error as { status?: number })?.status === 429;

      const waitTime = isRateLimit ? 10_000 : Math.pow(2, attempt) * 1_000;
      onStatus?.(
        `âš ï¸ API error. Retrying in ${waitTime / 1000}s (Attempt ${attempt + 1}/${maxRetries})â€¦`
      );
      console.warn(`[${provider}] attempt ${attempt} failed, waiting ${waitTime}msâ€¦`, error);

      await new Promise(resolve => setTimeout(resolve, waitTime));
    }
  }
  throw new Error(`API request to ${provider} failed after ${maxRetries} retries.`);
}